# LLM Evaluation Project Configuration

# Model Configuration
models:
  evaluator:
    provider: "vertex"
    parameters:
      model: "gemini-1.5-pro-002"
      temperature: 0
      max_tokens: 1024
      top_p: 1.0
      
  application:
    provider: "openai"
    parameters:
      model: "gpt-4o-mini"
      temperature: 1
      max_tokens: 2048
      top_p: 1.0
      

# Evaluation Configuration
evaluation:
  dataset:
    name: "story-gen"
  
  experiment:
    prefix: "experiment-llm-judges"
    num_repetitions: 1
    metadata:
      version: "1.0.4"
      revision_id: "alpha"

